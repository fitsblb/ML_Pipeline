# ğŸš€ Reproducible Machine Learning Pipeline with Real-Time Serving

## ğŸ¯ Project Overview

**Solving the ML Reproducibility Crisis**

Built to explore and solve real ML engineering challenges. This project demonstrates how modern MLOps tools can transform chaotic ML workflows into professional, reproducible systems with production-ready model serving.

**Problem Solved:** *"It works on my machine"* â†’ *"It works everywhere, reliably"*

**Tools**: DVC, MLflow, DagHub, Docker, Flask, Scikit-learn  
**Dataset**: Pima Indians Diabetes Database

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Data Pipeline â”‚    â”‚  Model Training â”‚    â”‚  Model Serving  â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ DVC Versioning  â”‚â”€â”€â”€â–¶â”‚ MLflow Tracking â”‚â”€â”€â”€â–¶â”‚  Flask API +    â”‚
â”‚ Automated Prep  â”‚    â”‚ Hyperparameter  â”‚    â”‚ Live Dashboard  â”‚
â”‚                 â”‚    â”‚ Optimization    â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   DagHub        â”‚    â”‚   Experiment    â”‚    â”‚   Docker        â”‚
â”‚   Integration   â”‚    â”‚   Comparison    â”‚    â”‚ Containerizationâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Complete MLOps workflow from raw data to production-ready API endpoint.**

![Architecture](../img/architecture.png)

## ğŸ“ Project Structure

```
ML_Pipeline/
â”œâ”€â”€ ğŸ“ .dvc/                          # DVC configuration and cache
â”œâ”€â”€ ğŸ“Š Data/                          # Dataset storage
â”œâ”€â”€ ğŸ“· img/                           # Images and screenshots
â”œâ”€â”€ ğŸ§  models/                        # Trained models and artifacts
â”œâ”€â”€ ğŸŒ serve/                         # Model serving components
â”œâ”€â”€ ğŸ“œ src/                           # Source code
â”œâ”€â”€ ğŸ§ª tests/                         # Testing suite
â”œâ”€â”€ ğŸ venv/                          # Virtual environment
â”œâ”€â”€ ğŸ³ .dockerignore                  # Docker ignore rules
â”œâ”€â”€ ğŸ”’ .env                           # Environment variables (MLflow credentials)
â”œâ”€â”€ ğŸ“‹ .gitignore                     # Git ignore rules
â”œâ”€â”€ ğŸ³ Dockerfile                     # Main pipeline container
â”œâ”€â”€ ğŸ”’ dvc.lock                       # DVC lock file
â”œâ”€â”€ ğŸ“„ dvc.yaml                       # Pipeline definition
â”œâ”€â”€ ğŸ“„ params.yaml                    # Hyperparameters & settings
â”œâ”€â”€ ğŸ“„ README.md                      # This documentation
â””â”€â”€ ğŸ“„ requirements.txt               # Python dependencies
```

![Project Structure](../img/Project%20structure.png)

## ğŸš€ Quick Start

### **Prerequisites**
- Docker installed
- Git repository access
- Python 3.10+ (for local development)

### **1. Clone and Setup**
```bash
git clone https://github.com/fitsblb/ML_Pipeline.git
cd ML_Pipeline

# Create environment file
echo "MLFLOW_TRACKING_URI=https://dagshub.com/fitsblb/ML_Pipeline.mlflow" > .env
echo "MLFLOW_TRACKING_USERNAME=your_username" >> .env
echo "MLFLOW_TRACKING_PASSWORD=your_token" >> .env
```

### **2. Run Complete Pipeline**
```bash
# Build and run the ML pipeline
docker build -t ml-pipeline .
docker run --rm -v %cd%:/app --env-file .env ml-pipeline
```

### **3. Deploy Model Server**
```bash
# Build serving container
docker build -t model-server -f serve/Dockerfile .

# Launch API server with live dashboard
docker run -p 8000:8000 model-server
```

### **4. Access Live Dashboard**
Open browser: **http://localhost:8000**

![Live Dashboard](../img/host_output.png)

## ğŸ§ª Testing the API

### **Health Check**
```bash
curl http://localhost:8000
# Response: "Model is ready to predict!"
```

### **Single Prediction**
```bash
curl -X POST http://localhost:8000/predict 
     -H "Content-Type: application/json" 
     -d '{
       "Pregnancies": 6,
       "Glucose": 148,
       "BloodPressure": 72,
       "SkinThickness": 35,
       "Insulin": 0,
       "BMI": 33.6,
       "DiabetesPedigreeFunction": 0.627,
       "Age": 50
     }'
```

**Response:**
```json
{"prediction": [1]}  // 1 = Diabetes Risk, 0 = No Diabetes
```

### **Multiple Test Cases**
```bash
# Run comprehensive testing
python tests/test_multiple.py
```

![Terminal Output](../img/terminal_output.png)

## ğŸ› ï¸ Technical Stack

| Tool | Purpose | Why This Tool |
|------|---------|---------------|
| **DVC** | Data & Model Versioning | Git for data - track large files efficiently |
| **MLflow** | Experiment Tracking | Compare runs, track metrics, log models |
| **DagHub** | Remote Collaboration | GitHub for ML - share data and experiments |
| **Scikit-learn** | ML Framework | Random Forest with hyperparameter tuning |
| **Python** | Implementation | Pandas, YAML configuration, pickle serialization |

## âœ¨ Key Features

### ğŸ” **Complete Reproducibility**
- One command reproduces entire pipeline
- Deterministic results with fixed random seeds
- Version-controlled data, code, and models

### ğŸ“Š **Smart Dependency Tracking**
- Automatic recomputation when dependencies change
- Skip unchanged stages for efficiency
- Clear visualization of pipeline dependencies

### ğŸ›ï¸ **Configurable Parameters**
- Centralized configuration in `params.yaml`
- Easy experimentation with different settings
- Parameter versioning and tracking

### ğŸš€ **Experiment Management**
- Track all runs with MLflow
- Compare model performance across experiments
- Remote experiment sharing via DagHub

### ğŸ‘¥ **Team Collaboration**
- Shared data storage with DVC
- Reproducible environments
- Clear pipeline documentation

## ğŸ”„ Pipeline Stages

### 1ï¸âƒ£ **Preprocessing Stage**
```bash
python src/preprocess.py
```
- Loads raw diabetes dataset
- Handles missing values and outliers
- Feature scaling and engineering
- Outputs cleaned dataset

### 2ï¸âƒ£ **Training Stage**
```bash
python src/train.py
```
- Hyperparameter tuning with GridSearchCV
- Random Forest model training
- MLflow experiment logging
- Model serialization

### 3ï¸âƒ£ **Evaluation Stage**
```bash
python src/evaluate.py
```
- Model performance evaluation
- Metrics calculation and logging
- Results visualization

## ğŸ“Š Results

The pipeline achieves:
- **Accuracy**: ~85% on diabetes prediction
- **Reproducibility**: 100% identical results across runs
- **Efficiency**: Only recomputes changed stages
- **Scalability**: Easy to add new features or models

## ğŸ”§ Experimentation

Modify parameters in `params.yaml` and rerun:

```yaml
train:
  random_state: 42
  hyperparameter_grid:
    n_estimators: [100, 200, 300]  # Try more trees
    max_depth: [5, 10, 15, null]   # Experiment with depth
    min_samples_split: [2, 5, 10]  # Adjust splitting
```

```bash
# Pipeline automatically detects parameter changes
dvc repro  # Only reruns affected stages
```

## ğŸ“ Key Learnings

### **Technical Insights:**
- DVC transforms chaotic data workflows into organized pipelines
- MLflow provides crucial experiment tracking for ML iterations
- Proper dependency management eliminates "works on my machine" issues
- Parameter externalization enables systematic experimentation

### **MLOps Best Practices:**
- Version control everything: data, code, models, and configurations
- Automate pipeline execution and dependency tracking
- Centralize experiment tracking for team collaboration
- Design for reproducibility from day one

### **Engineering Principles:**
- Separation of concerns: preprocessing, training, evaluation
- Configuration-driven development with `params.yaml`
- Fail-fast validation with proper error handling
- Documentation-as-code approach

## ğŸ›¡ï¸ Production Considerations

This pipeline demonstrates production-ready practices:
- **Environment isolation** with `requirements.txt`
- **Credential management** with environment variables
- **Error handling** and logging throughout
- **Modular design** for easy maintenance and testing
- **CI/CD readiness** with single-command execution

## ğŸ”® Future Enhancements

- [ ] Add automated model validation
- [ ] Implement A/B testing framework
- [ ] Add data drift detection
- [ ] Create web API for model serving
- [ ] Add automated model retraining triggers

---

## ğŸ™ Acknowledgments

Built to explore and solve real ML engineering challenges. This project demonstrates how modern MLOps tools can transform chaotic ML workflows into professional, reproducible systems.

**Tools**: DVC, MLflow, DagHub, Scikit-learn  
**Dataset**: Pima Indians Diabetes Database

---

*"In ML, reproducibility isn't a nice-to-haveâ€”it's the foundation of trustworthy AI systems."*
